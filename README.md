# AvatarLab-G432-PS25
An end-to-end system that generates **AI-driven avatars** by combining **voice cloning** and **talking head video generation** using advanced open-source models.
## ğŸ§© Architecture & Workflow

![Architecture Diagram](./samples/Architecture.png)
![Workflow Diagram](./samples/workflow.jpg)

---

## ğŸ¬ Output Videos

- ğŸ”¹ [Sample Video 1](./samples/output1.mp4)
- ğŸ”¹ [Sample Video 2](./samples/output2.mp4)


---

## ğŸ§© Features

- Upload text and your voice sample to clone your voice.
- Upload an image or selfie to animate using your voice.
- Backend integration with:
  - `StyleTTS2` for **voice cloning**
  - `SadTalker` for **talking head generation**
- Video generation using **FFmpeg**
- JWT-based user authentication
- MongoDB storage for user and video history
- Fully functional frontend using React + TypeScript

---

## ğŸ§ª Tested Models (TTS + Video Generation)

We tested 10+ models for both speech synthesis and talking head video generation:

| Model Name | Type            | Status | Notes                                |
|------------|-----------------|--------|--------------------------------------|
| StyleTTS2  | TTS             | âœ… Used | High quality, fast                   |
| SadTalker  | Video           | âœ… Used | Stable, open-source                  |
| XTTTS      | TTS             | âŒ emotion |                                      |
| Coqui TTS  | TTS             | âŒ Poor quality |                              |
| OpenVoice  | TTS             | âŒ Unstable |                                      |
| Bark       | TTS             | âŒ Very slow |                                      |
| Small-E    | TTS             | âŒ Experimental |                                  |
| Tortoise TTS | TTS             | âŒ Slow, GPU required |                      |
| DiffTalk   | Video           | âŒ Expired checkpoints |                         |
| PC-AVS     | Video           | âŒ Model complexity |                          |
| DreamTalker | Video           | âŒ mid quality |                            |
| Memo       | Video           | âŒ Output quality low |                        |
| AniTalker  | Video           | âŒ Unrealistic movements |                       |

ğŸ§  **Why We Chose StyleTTS2 + SadTalker?**
ğŸ§‘â€ğŸ¤ **StyleTTS2**: lightweight, great output even without GPU
ğŸ¥ **SadTalker**: better control of facial movements, easy integration
âš¡ **Other models were either:**
- Too large for CPU inference
- Poor in quality
- Had dependency or checkpoint errors

---

## ğŸ› ï¸ Tech Stack

- Frontend: React + TypeScript + Tailwind
- Backend: Node.js + Express
- Model Server: FastAPI (Python)
- Database: MongoDB
- Video Processing: FFmpeg

---

## ğŸŒ Deployment

| Layer         | Tool / Platform          |
|---------------|--------------------------|
| Frontend      | Vercel                   |
| Backend       | Render                   |
| Model Server  | Localhost / Cloud VM     |
| Storage       | Local folders (temp)     |

---

## ğŸ‘¨â€ğŸ’» Team Members (Alphabetical Order)

- Abhishek Kumar
- Anand Sai
- Hrushikesh Sai
- Samuel
- Sowmith
- Yashwanth

---

## ğŸ“‚ Folder Structure (Sample)

```bash
/AvatarLab
â”‚
â”œâ”€â”€ /client               # React frontend
â”œâ”€â”€ /server               # Express backend
â”œâ”€â”€ /model-server         # FastAPI + models
â”œâ”€â”€ /samples/outputs      # Generated avatar videos 
â””â”€â”€ README.md